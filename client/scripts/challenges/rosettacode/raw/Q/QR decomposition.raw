
/* eslint spaced-comment: 0 */
/* eslint no-redeclare: 0 */
/* eslint no-undef: 0 */
/* eslint no-unused-vars: 0 */

const assert = require('chai').assert;

/// title: QR decomposition
/// type: rosetta-code

/// categories:
/// Mathematics

/// difficulty: ?

/// benchmark:
replaceWithActualFunctionHere;

/// description:
/// <div class="rosetta">
/// <p class="rosetta__paragraph">Any rectangular $m \times n$ matrix $\mathit A$ can be decomposed to a product of an orthogonal matrix $\mathit Q$ and an upper (right) triangular matrix $\mathit R$, as described in <a class="rosetta__link--wiki" href="https://en.wikipedia.org/wiki/QR decomposition" title="wp: QR decomposition">QR decomposition</a>.</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--bold">Task</span></p><br/><p class="rosetta__paragraph">Demonstrate the QR decomposition on the example matrix from the <a class="rosetta__link--wiki" href="https://en.wikipedia.org/wiki/QR_decomposition#Example_2" title="wp: QR_decomposition#Example_2">Wikipedia article</a>:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$A = \begin{pmatrix}</span></p>
/// <p class="rosetta__paragraph">12 & -51 & 4 \\</p>
/// <p class="rosetta__paragraph">6 & 167 & -68 \\</p>
/// <p class="rosetta__paragraph">-4 & 24 & -41 \end{pmatrix}$</p><br/><p class="rosetta__paragraph">and the usage for linear least squares problems on the example from <a class="rosetta__link--rosetta" href="http://rosettacode.org/wiki/Polynomial_regression" title="Polynomial_regression">Polynomial_regression</a>. The method of <a class="rosetta__link--wiki" href="https://en.wikipedia.org/wiki/ Householder transformation" title="wp:  Householder transformation">Householder reflections</a> should be used:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--bold">Method</span></p><br/><p class="rosetta__paragraph">Multiplying a given vector $\mathit a$, for example the first column of matrix $\mathit A$, with the Householder matrix $\mathit H$, which is given as</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H = I - \frac {2} {u^T u} u u^T$</span></p><br/><p class="rosetta__paragraph">reflects $\mathit a$ about a plane given by its normal vector $\mathit u$. When the normal vector of the plane $\mathit u$ is given as</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$u = a - \|a\|_2 \; e_1$</span></p><br/><p class="rosetta__paragraph">then the transformation reflects $\mathit a$ onto the first standard basis vector</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$e_1 = [1 \; 0 \; 0 \; ...]^T$</span></p><br/><p class="rosetta__paragraph">which means that all entries but the first become zero. To avoid numerical cancellation errors, we should take the opposite sign of $a_1$:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$u = a + \textrm{sign}(a_1)\|a\|_2 \; e_1$</span></p><br/><p class="rosetta__paragraph">and normalize with respect to the first element:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$v = \frac{u}{u_1}$</span></p><br/><p class="rosetta__paragraph">The equation for $H$ thus becomes:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H = I - \frac {2} {v^T v} v v^T$</span></p><br/><p class="rosetta__paragraph">or, in another form</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H = I - \beta v v^T$</span></p><br/><p class="rosetta__paragraph">with</p>
/// <p class="rosetta__paragraph"><span class="rosetta__text--indented">:$\beta = \frac {2} {v^T v}$</span></p><br/><p class="rosetta__paragraph">Applying $\mathit H$ on $\mathit a$ then gives</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H \; a = -\textrm{sign}(a_1) \; \|a\|_2 \; e_1$</span></p><br/><p class="rosetta__paragraph">and applying $\mathit H$ on the matrix $\mathit A$ zeroes all subdiagonal elements of the first column:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H_1 \; A = \begin{pmatrix}</span></p>
/// <p class="rosetta__paragraph">r_{11} & r_{12} & r_{13} \\</p>
/// <p class="rosetta__paragraph">0    & *    & * \\</p>
/// <p class="rosetta__paragraph">0    & *    & * \end{pmatrix}$</p><br/><p class="rosetta__paragraph">In the second step, the second column of $\mathit A$, we want to zero all elements but the first two, which means that we have to calculate $\mathit H$ with the first column of the <span class="rosetta__text--italic">submatrix</span> (denoted *), not on the whole second column of $\mathit A$.</p><br/><p class="rosetta__paragraph">To get $H_2$, we then embed the new $\mathit H$ into an $m \times n$ identity:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H_2 = \begin{pmatrix}</span></p>
/// <p class="rosetta__paragraph">1 & 0 & 0 \\</p>
/// <p class="rosetta__paragraph">0 & H & \\</p>
/// <p class="rosetta__paragraph">0 &   & \end{pmatrix}$</p><br/><p class="rosetta__paragraph">This is how we can, column by column, remove all subdiagonal elements of $\mathit A$ and thus transform it into $\mathit R$.</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H_n \; ... \; H_3 H_2 H_1 A = R$</span></p><br/><p class="rosetta__paragraph">The product of all the Householder matrices $\mathit H$, for every column, in reverse order, will then yield the orthogonal matrix $\mathit Q$.</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$H_1 H_2 H_3 \; ... \; H_n = Q$</span></p><br/><p class="rosetta__paragraph">The QR decomposition should then be used to solve linear least squares (<a class="rosetta__link--rosetta" href="http://rosettacode.org/wiki/Multiple regression" title="Multiple regression">Multiple regression</a>) problems $\mathit A x = b$ by solving</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$R \; x = Q^T \; b$</span></p><br/><p class="rosetta__paragraph">When $\mathit R$ is not square, i.e. $m > n$ we have to cut off the $\mathit m - n$ zero padded bottom rows.</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$R =</span></p>
/// <p class="rosetta__paragraph">\begin{pmatrix}</p>
/// <p class="rosetta__paragraph">R_1 \\</p>
/// <p class="rosetta__paragraph">0 \end{pmatrix}$</p><br/><p class="rosetta__paragraph">and the same for the RHS:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$Q^T \; b =</span></p>
/// <p class="rosetta__paragraph">\begin{pmatrix}</p>
/// <p class="rosetta__paragraph">q_1 \\</p>
/// <p class="rosetta__paragraph">q_2 \end{pmatrix}$</p><br/><p class="rosetta__paragraph">Finally, solve the square upper triangular system by back substitution:</p><br/><p class="rosetta__paragraph"><span class="rosetta__text--indented">:$R_1 \; x = q_1$</span></p><br/></div>

/// challengeSeed:
function replaceMe (foo) {
  // Good luck!
  return true;
}

/// solutions:


/// rawSolutions:
null

/// tail:
const replaceThis = 3;

/// tests:
assert(typeof replaceMe === 'function', 'message: <code>replaceMe</code> is a function.');
